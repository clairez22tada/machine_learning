{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Notebook 7.2: Decision tree midpoint split for Boston dataset\n",
    "\n",
    "This notebook will continue to help you to wrap your head around how a decision tree might best be implemented. In this lab we take a quick look at a basic `TreeNode` class, and then do a quick review of recursion.\n",
    "\n",
    "## Tools\n",
    "\n",
    "#### Libraries:\n",
    "\n",
    "- numpy: for processing\n",
    "- pandas\n",
    "- lolviz: for visualization of graphs\n",
    "\n",
    "#### Datasets:\n",
    "\n",
    "Boston housing \n",
    "\n",
    "## Setup\n",
    "\n",
    "For this lab you will need another library called `lolviz` which you can install within the Jupyter notebook, but you first should first install `graphviz`, which is easy to do on a Mac.\n",
    "\n",
    "```\n",
    "brew install graphviz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from lolviz import treeviz\n",
    "\n",
    "from types import SimpleNamespace\n",
    "def load_boston(return_X_y=False):\n",
    "    \"\"\"Replacement function for loading in Boston House Prices\"\"\"\n",
    "    df = pd.read_csv('boston_house_prices.csv')\n",
    "    X = df.drop(columns=['MEDV'])\n",
    "    y = df['MEDV'].to_numpy()\n",
    "\n",
    "    if return_X_y:\n",
    "        return X, y \n",
    "    \n",
    "    dataset  = SimpleNamespace(data=X, target=y)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Node class\n",
    "\n",
    "Let's take our tree node and enhance it a little with some extra attributes to make it more like a decision tree node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode: # acts as decision node and leaf. it's a leaf if split is None\n",
    "  def __init__(self, split=None, prediction=None, left=None, right=None):\n",
    "    self.split = split\n",
    "    self.prediction = prediction\n",
    "    self.left = left\n",
    "    self.right = right\n",
    "  def __repr__(self):\n",
    "    return str(self.value)\n",
    "  def __str__(self):\n",
    "    return str(self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boston midpoint stump\n",
    "\n",
    "The following demonstrates a simple stump: all of the data passed to `stumpfit` is simply split into two pieces using the midpoint of `x`, as long as there is more than one observation (or more than one unique value of `x`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stumpfit(x, y):\n",
    "    if len(x)==1 or len(np.unique(x))==1: # if one x value, make leaf\n",
    "        return TreeNode(prediction=y[0])\n",
    "    split = (min(x) + max(x)) / 2 # midpoint\n",
    "    t = TreeNode(split=split)\n",
    "    t.left = TreeNode(prediction=np.mean(y[x<split]))\n",
    "    t.right = TreeNode(prediction=np.mean(y[x>=split]))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X), \"records\")\n",
    "age = X.AGE#[:,6]\n",
    "stump = stumpfit(age,y)\n",
    "treeviz(stump)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boston midpoint tree\n",
    "\n",
    "Now we can modify `stumpfit` a little bit so that instead of only splitting the data once, we will recursively split the data, using the midpoint of `x`, as long as there is more than one observation or more than one unique value in `x`. This will continue splitting the data into two pieces until the stopping condition is met, and will result in a much larger tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treefit(x, y):\n",
    "    if len(x)==1 or len(np.unique(x))==1: # if one x value, make leaf\n",
    "        return TreeNode(prediction=y[0])\n",
    "    split = (min(x) + max(x)) / 2 # midpoint\n",
    "    t = TreeNode(split=split)\n",
    "    t.left  = treefit(x[x<split],  y[x<split])\n",
    "    t.right = treefit(x[x>=split], y[x>=split])\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = treefit(age,y)\n",
    "treeviz(root)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic method call demo\n",
    "\n",
    "This is simply an example of how you can have methods of the same name for different classes, and the correct one will be called depending on the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def hello(self):\n",
    "        print(\"decision\")\n",
    "\n",
    "class LeafNode:\n",
    "    def hello(self):\n",
    "        print(\"leaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DecisionNode()\n",
    "d.hello()\n",
    "l = LeafNode()\n",
    "l.hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x):\n",
    "    x.hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo(l)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting back to the beginning\n",
    "\n",
    "When doing recursion it can be confusing to track how results are returned back to earlier calls of the function. Sometimes it is easiest to draw a picture, or print something to the screen, to track the function calls and returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    g()\n",
    "    print(\"back from g()\")\n",
    "    \n",
    "def g():\n",
    "    h()\n",
    "    print(\"back from h()\")\n",
    "\n",
    "def h():\n",
    "    print(\"hi I'm h!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f()\n",
    "print(\"back from f()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f calls g calls h and it remembers where it came from. Just imagine that f, g, and h are the same function and you'll see that recursion also remembers where it came from.\n",
    "\n",
    "Where to return is tracked per function **call** not per function **definition**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "31d7989649452b8ff5b252a3e34caf45e4ffd8a5787fe28fc2ce0245f11b7782"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
